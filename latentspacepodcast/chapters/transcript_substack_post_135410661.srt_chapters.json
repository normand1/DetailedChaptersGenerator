{"chapters": [{"title": "Intro", "startTime": 0}, {"title": "FlashAttention", "startTime": 329}, {"title": "Hazy Research", "startTime": 971}, {"title": "Academia vs Industry", "startTime": 1503}, {"title": "Hardware Lottery", "startTime": 1970}, {"title": "Transformer Alternatives", "startTime": 2255}, {"startTime": 2680, "url": "https://www.latent.space/p/llama2#details", "title": "LLaMA"}, {"startTime": 334, "url": "https://arxiv.org/abs/2205.14135", "title": "FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness"}, {"startTime": 1726, "url": "https://crfm.stanford.edu/2023/07/17/flash2.html", "title": "FlashAttention-2"}, {"startTime": 3165, "url": "https://www.together.xyz/", "title": "Together AI"}, {"startTime": 1186, "url": "https://hazyresearch.stanford.edu/", "title": "Hazy Research"}, {"startTime": 138, "url": "https://www.isattentionallyouneed.com/", "title": "Is Attention All You Need?"}, {"startTime": 1726, "url": "https://github.com/NVIDIA/cutlass/discussions/787", "title": "Nvidia CUTLASS 3"}, {"startTime": 2581, "url": "https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-recurrent-neural-networks", "title": "Recurrent Neural Networks (RNNs)"}, {"startTime": 24, "url": "https://decibel.vc/", "title": "Decibel Partners"}], "version": "1.0.0"}