{"chapters": [{"title": "Tri's background", "startTime": 0}, {"title": "FlashAttention\u2019s deep dive", "startTime": 138}, {"title": "How the Hazy Research group collaborates across theory, systems, and applications", "startTime": 1041}, {"title": "Evaluating models beyond raw performance", "startTime": 1500}, {"title": "FlashAttention-2", "startTime": 1620}, {"title": "CUDA and The Hardware Lottery", "startTime": 1800}, {"startTime": 2680, "url": "https://www.latent.space/p/llama2#details", "title": "LLaMA"}, {"startTime": 272, "url": "https://lu.ma/llm-paper-club", "title": "here"}, {"startTime": 138, "url": "https://arxiv.org/abs/2205.14135", "title": "FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness"}, {"startTime": 64, "url": "https://www.together.xyz/", "title": "Together AI"}, {"startTime": 1041, "url": "https://www.isattentionallyouneed.com/", "title": "Is Attention All You Need?"}, {"startTime": 138, "url": "https://github.com/NVIDIA/cutlass/discussions/787", "title": "Nvidia CUTLASS 3"}, {"startTime": 2581, "url": "https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-recurrent-neural-networks", "title": "Recurrent Neural Networks (RNNs)"}], "version": "1.0.0"}