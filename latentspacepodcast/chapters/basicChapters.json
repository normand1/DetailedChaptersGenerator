{"chapters": [{"title": "Tri's background", "startTime": 0
        }, {"title": "FlashAttentionâ€™s deep dive", "startTime": 2
        }, {"title": "How the Hazy Research group collaborates across theory, systems, and applications", "startTime": 17
        }, {"title": "Evaluating models beyond raw performance", "startTime": 25
        }, {"title": "FlashAttention-2", "startTime": 27
        }, {"title": "CUDA and The Hardware Lottery", "startTime": 30
        }, {"title": "Researching in a fast-changing market", "startTime": 35
        }, {"title": "Promising transformer alternatives like state space models and RNNs", "startTime": 37
        }, {"title": "The spectrum of openness in AI models", "startTime": 43
        }, {"title": "Practical impact of models like LLAMA2 despite restrictions", "startTime": 47
        }, {"title": "Incentives for releasing open training datasets", "startTime": 49
        }, {"title": "Lightning Round", "startTime": 53
        }], "version": "1.0.0"}