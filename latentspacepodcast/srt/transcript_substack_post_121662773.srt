23
00:00:00,000 --> 00:02:30,000
*  Shreya's Intro

24
00:02:30,000 --> 00:05:50,000
*  What's Guardrails AI?

25
00:05:50,000 --> 00:10:00,000
*  Why XML instead of YAML or JSON?

26
00:10:00,000 --> 00:14:00,000
*  SQL as a validation language?

27
00:14:00,000 --> 00:16:00,000
*  RAIL composability and package manager?

28
00:16:00,000 --> 00:23:50,000
*  Using Guardrails for agents

29
00:23:50,000 --> 00:31:30,000
*  Guardrails "contracts" and guarantees

30
00:31:30,000 --> 00:40:00,000
*  SLAs for LLMs

31
00:40:00,000 --> 00:43:00,000
*  How to prioritize as a solo founder in open source

32
00:43:00,000 --> 00:46:00,000
*  Guardrails open source community involvement

33
00:46:00,000 --> 00:50:00,000
*  Working with Ian Goodfellow

34
00:50:00,000 --> 00:52:00,000
*  Research coming out of Stanford

35
00:52:00,000 --> 00:00:00,000
*  Lightning Round

38
00:00:00,000 --> 00:00:00,000
Alessio:  Hey everyone. Welcome to the Latent Space Podcast. This is Alessio partner and CTO-in-Residence at Decibel Partners. I'm joined by my cohost Swyx, writer and editor of Latent Space.

44
00:01:00,000 --> 00:00:00,000
So yeah, I, it's felt this way where  it's almost shared. It's almost changed the world for as long as I've been working in it.

50
00:02:00,000 --> 00:00:00,000
I think another. More personal skill, which I  think I'm like kind of okay for an amateur and that isn't on my LinkedIn is, is pottery. So I really enjoy pottery and yeah, don't know how to slot that in amongst, like, all of the AI. So that's not in there. 

56
00:03:00,000 --> 00:00:00,000
And then as a developer like I can tell that there's very few tools available for me to like, get this to, you know cooperate  with me, like get it to follow directions, etc. And the only tool I really have is this prompt. And there's only so, so far you can go with like, putting instructions in like caps, adding a bunch of exclamations and being like, follow my instructions. Like give me this output this way. 

59
00:04:00,000 --> 00:00:00,000
As I was thinking of this, I was like, this should be very extensible, very flexible so that there's a bunch of use cases that can be handled, et cetera. But the need really like, kind of came up from my own from my own, like I was basically solving for my own pain points.

63
00:05:00,000 --> 00:00:00,000
And then once you get that output all of the specification criteria you entered is like  systematically validated and like corrected. And there's a bunch of like tools in there that allow you a lot of control to like handle failures much more gracefully. So that's in a nutshell what guardrails does.

70
00:06:00,000 --> 00:00:00,000
Shreya: So it is I didn't start out with it is the truth. Like, I think I started out from this code first framework service initially like Python classes, et cetera. And I was like, wait, this is too verbose. This is like I, as I'm thinking about what I want, I truly just  want this is like, this is what this dictionary should look like for me, right?

74
00:07:00,000 --> 00:00:00,000
You know, and, and it gets you like better outputs. You can add in like what the correctness criteria or what the validity criteria is for this field, et  cetera. That also gets like passed through to the prompt, et cetera. And these are all like, Properties for a single field, right? But fields themselves can be containers and can have like other nested like fields within them.

77
00:08:00,000 --> 00:00:00,000
Like maybe I don't care about it as much. Right. So, so that seemed pretty elegant to me. That said, I've talked to a lot of people who are very opinionated about it. My, like, the thing that I was optimizing for was essentially that it seemed clean to me compared to like other things I tried out and seemed as close to English as  possible.

84
00:09:00,000 --> 00:00:00,000
 But now like you can get not all the way, but like a decent amount of way there, like with just English. And that is very, very powerful. So it is a design goal to like have like essentially low floor, high ceiling is, was like absolutely a design goal. So if, if you're used to plain English and prompting using Chad PK with plain English, then you can it should be very easy for you to kind of like pick this up and there's not a lot of gap there, but like you can also build like pretty complex workflows with guardrails and it's like very adaptable in that way.

87
00:10:00,000 --> 00:00:00,000
 Like what is the, where is a visual interface for building something like this? But I feel like that's, that's another reason for why XML was appealing, because it's essentially like a document structuring, like it's a way to think about like documents as trees, right? And so again, if you're thinking about like what a visual interface would be, then maps going nicely to xml.

92
00:11:00,000 --> 00:00:00,000
So I think that was part of the inspiration for not exploring sql. I'd looked into it very briefly, but I mean, I think for my, for my own workflows,  I wanted to make it like as easy as possible to like wrap whatever LLM API calls you make. And, and to me that design was in markup or like in XML, where you just define your desired

98
00:12:00,000 --> 00:00:00,000
And it's kind of has that approach of  taking a templating XML like language to describe something that was typically previously described in Code. I wonder if you took any inspiration from that? If you want to just exchange notes on anything from that like made React successful. Cuz I, I spent a few years studying that.

103
00:13:00,000 --> 00:00:00,000
I think that was an inspiration. So I basically looked at like,  If you're familiar with Guardrails and you know that you can insert like dynamic scripting into a rail specification, so you can register custom validators within rail. You can maybe have like essentially code snippets where things are like lists or things are like dynamically generated array, et cetera, within GAR Rail.

107
00:14:00,000 --> 00:00:00,000
Can I import a guardrails thing from into another guardrails project?  I see. That paves the way for guardrails package managers or libraries or Right. Reusable components, essentially. I think that's

112
00:15:00,000 --> 00:00:00,000
So each node in your graph or tree or in your dag would essentially have like a guardrails config associated with it. And you can kind of like use your favorite chaining libraries, like nine chain, et cetera, to like then compose this further together.  I think I've seen like one of the first actually community projects that was like built using guardrails, like had chaining and then had like different rails for each node of that chain.

118
00:16:00,000 --> 00:00:00,000
Alessio: I was just thinking about this because if you think about Baby a gi mm-hmm. And some of these projects mm-hmm. A lot of them are just loops of prompts. Yeah. You know so I can see a future  in which. A lot of these loops are kind off the shelf thing and then you bring your own rails mm-hmm.

123
00:17:00,000 --> 00:00:00,000
So essentially like the  interesting thing about the agent framework for me is like how we will kind of like break this up into smaller tasks and then like assign those guarantees kind of at e each outputs. It's a problem that I've been like thinking about, but it's also like frankly a hard problem to solve because you're.

127
00:18:00,000 --> 00:00:00,000
I think like that's  the, that would be like super compelling to me, and that is kind of like the solution that I would be interested in putting out. But yeah, it's, it's something that I'm thinking about for sure. I'm

131
00:19:00,000 --> 00:00:00,000
Shreya: Yeah. I think that's a great question, and I think just this way of thinking about invariables, et cetera is something that is very core to how I've been thinking about this problem and like why I also chose to work on this problem. So, I think again, and this is like guided by some of my past experience in machine learning and also kind of like looking at like how these problems are, how like other applications that I've had a lot  of interest, like how some of the ML challenges have been solved in there.

140
00:20:00,000 --> 00:00:00,000
I think there's like known recipes for making  this work. And it's, it's like a problem like once, essentially it's a problem of just kind of like a lot of experimentation and like finding exactly what configurations kind of get you there. So that will also arrive, both of those things combined, you know will like drive down the cost of running inference on these models.

143
00:21:00,000 --> 00:00:00,000
Combined with this, System where you don't even actually own the model yourself, right? So the models are updated from under you all the time. Like for building guardrails, like I had to do a bunch of prompt engineering, right? So that users get like really great structured outputs, like share of the bat  without like having to do any work.

146
00:22:00,000 --> 00:00:00,000
And temperature zero does not equal like seed zero or fixed seed rather. And so even with all of the trends that we're gonna see arriving pretty soon over the next year, if not sooner, this idea of like determinism reproducibility is not gonna change, right? Ignoring reproducibility is a whole other problem of like the really, really, really long tail of like inputs and outputs that are not covered by, by tests and by training data,  et cetera.

150
00:23:00,000 --> 00:00:00,000
It's my, it's my kind of my job to like keep track of, keep it, yeah. So I'm sure that's, If that's the case that like there's some internal guard rails, and I'm sure that that would be a trend that we would kind of see. But even with that there's like a ton of use cases and a  ton of kind of like application areas where like there's different requirements from different types of guard rails are valuable in different requirements.

155
00:24:00,000 --> 00:00:00,000
Bug-free Python. And that's, that's also pretty,  pretty cool. You have similar to document and extracted summary sentences match. Which I think is, is like don't hallucinate,

161
00:25:00,000 --> 00:00:00,000
Yeah, the core proposition. I think that is like very popular, but that's also kind of like the first order. Problem that people are kind of solving. I think the sequel thing, for example, it's very exciting because I had just released this like two days ago and then I already got some inbound with like people kinda swapping, like building these products and of swapping it out internally and you know,  getting a lot of value out of what the sequel bug-free SQL provides.

165
00:26:00,000 --> 00:00:00,000
I think there's other kind of like, You can build pretty complex systems with this. So other things in there are like it takes  information about your database and then injects it into the prompt with like, here's the schema of this table. It automatically, like given a national language query, it finds like what the most similar examples are from the history of like, serving this model and like injects those into the prompt, et cetera.

170
00:27:00,000 --> 00:00:00,000
Yeah, so I think like, here's where this idea of like, it doesn't have to be like, you don't have to send every request to your L so you're sampling. Okay. So you can essentially figure out, so for example, like there's like how what guardrails essentially does is there's like corrective actions and re-asking is like one of those corrective actions,  right?

173
00:28:00,000 --> 00:00:00,000
But you can think about like other ways to handle disgracefully, right? Like essentially looking at essentially a fuzzy matching with like the existing table names in the repository and in, in the database. And you know, like matching any incorrect names to that. And so you can think of like merging this re-asking thing with like, other error handling things that like smaller, easier errors are able, you can handle them programmatically by just Doing this in like the more patching, patching or I, I guess the more like  classical ML way essentially, like not the super fancy deep learning is like, I think ML 2.0.

178
00:29:00,000 --> 00:00:00,000
So this is very  easy to do just locally. Right. Like, so there's like different ways essentially to kind of like handle this, which makes for like a more compelling way to build these

184
00:30:00,000 --> 00:00:00,000
This was the output of those validations. This  was any corrective actions, et cetera, that were taken. And I think that's like very, like as a developer, like, I'm so happy to see that I use these logs like personally as well.

189
00:31:00,000 --> 00:00:00,000
So yeah, thinking about that problem. Don't have anything on there yet, but, but I do really like this idea of really as a developer you're just like, you really want like all the visibility you can get into what's,  what's happening right. Under the hood. And I wanna be able to provide that. Yeah.

196
00:32:00,000 --> 00:00:00,000
Shreya: Yeah, the copy example is interesting because  I think for any of these things, the SLAs are purely on like content and output, not on time. I don't guardrails I don't think even can make any guarantees on the time that it'll take to make these external API calls. But like, even within quality, it's this idea of like, if you're able to communicate what you desire.

199
00:33:00,000 --> 00:00:00,000
So you can say that let's say like length or readability is a  guarantee. So some of the updates that I pushed today on, on summarization and like specific guards for summarization, one of them essentially was that like the reading time for the summary should be within like some certain amount, right?

204
00:34:00,000 --> 00:00:00,000
Like you already  see that, Ooh, with open AI today when some people complain that too many of the responses have too much like, Well actually in it where it's like, oh, you ask a question, it's like, but you should remember that's actually not good. And remember this other side of the story and, and all of that.

208
00:35:00,000 --> 00:00:00,000
And so within authenticity, like why conventional models were not good for them is that they already have a lot of like quote unquote guardrails right. To, to I guess like  appeal to like certain certain sections of the audience to essentially be very cleaned up and then that was like an undesirable trade because that, for them, like, almost took away from that authenticity, et cetera.

211
00:36:00,000 --> 00:00:00,000
And so how Guardrail is kind of designed or, or my intention with designing is that here's this way of breaking down what this problem is, right? Of like getting some determinism, getting some guarantees from your LM outputs.  And you can use this framework and like go crazy with it. Like build whatever you want, right?

215
00:37:00,000 --> 00:00:00,000
Do not give any other alternative to what we do. Yeah. How do you see all these things come together? Like, do you see guardrails as something that not only helps with the prompting, but also helps with bringing external data into these things, and especially with agents going on any website, do you see each provider having like their own  guardrail where it's like, Hey, this is what you can expect from us, or this is what we want to provide?

220
00:38:00,000 --> 00:00:00,000
Like let's say I have this running in production and then turns out that there was like some sort of leakage, et cetera, and you know, like my bot has actually been talking about like all of my competitors forever,  right? Like, that's a, that's a substantial risk. And so just this idea of like needing this like post-hoc validation to ensure deterministically that like it does what you want it to do is like, just so is like.

224
00:39:00,000 --> 00:00:00,000
Mm-hmm. And then you also do re-asking in all the other stuff post, I dunno what the pipeline is in, in, in your terminology. So essentially you have an API wrapper for open ai.completion.com dot create. But so does LangChain, so does Hellicone so does everyone I can name like five other people who are all fighting essentially for  the base layer, LLM API wrapper.

229
00:40:00,000 --> 00:00:00,000
And so, yeah, it's, I think like I'm pretty focused on this problem of like what is the guardrail that you would wanna build for a certain applications? So it's valuable real estate. I'm sure that people don't own  it.

236
00:41:00,000 --> 00:00:00,000
Combined with that is like a feature request I get or maybe some bugs, et cetera, that folks report. So I'm pretty focused on like any failures, any  feature requests from the community. So if those come up, I th those tend to Trump like anything else that I'm working on. But outside of that I have like this whole pool of ideas and like pool of features I wanna build and I kind of.

240
00:42:00,000 --> 00:00:00,000
Swyx: of the levers, how do you, like, let's just say in like a typical week, is it like 50%  calls with partners mm-hmm. And potential users and just understanding your use cases and the 50% building would you move that, that percentage anyway anywhere?

244
00:43:00,000 --> 00:00:00,000
So I think I did a lot of that, like. Immediately after the release, like talking to a lot of teams and talking to a lot of users. I think since then, I basically feel like I have a fair idea of like, you know what's great about it, what's mediocre about it, and what's like, not good about it? And that helps kind of guide my prioritization list of like what I  wanna ship and what I wanna build.

249
00:44:00,000 --> 00:00:00,000
You know, I have like feature requests and I have  contributors, but I think right now, like I'm doing the bulk of like supporting those feature requests, et cetera. So I think a goal for me, and I remember we chatted about this as well you know, when we, when we spoke last, we're just like, okay.

252
00:45:00,000 --> 00:00:00,000
And so that's actually, frankly, been like pretty fun as well to see the community be like opinionated about like, here's how I'm doing it and like, this works for me, this doesn't work for me, et cetera. So that's been like new for me as well. Like, I  think I am my previous company we also had like open source project and it was built on open source, but like, this is the first time that I've created a project with an open source project with like that level of engagement.

260
00:46:00,000 --> 00:00:00,000
This we talked about in variance earlier, and I do think that this is a, like being able to, like, I think if, if there's a contraction or a correction and  the, these LMS like don't have the kind of impact that we're, we're all hoping they would, I think it would be because of like, this problem because people kind of find that it's not as useful when it's running at very large scales when it's running in production, et cetera.

265
00:47:00,000 --> 00:00:00,000
So this was, I think I'm gonna mess up between 1215, I think 14, 15 ish if I remember correctly. So he basically created gans as a PhD student. As a PhD student. And he has a pretty interesting story of like how he thought of them and how  he kind of, Built the, and I I'm sure there's like interviews in like podcasts, et cetera with him where he talks about it, where like, how he got the idea for it and how he kind of like wrote the paper and did the experiments.

271
00:48:00,000 --> 00:00:00,000
Alessio: I didn't see that. Oh, okay. I think he basically, apple was like, you gotta go  back to the office.

279
00:49:00,000 --> 00:00:00,000
Shreya: I think the, the non-technical stuff, which  was I think truly made him such a fantastic manager. But when I went to Apple, I was, you know maybe a year outta school outta my job at that point.

283
00:50:00,000 --> 00:00:00,000
Mm-hmm. And the fastest way to solve this is the most, is the most correct way to do it. And like,  yeah, I truly, like, he's one of my favorite people. And I truly enjoyed working with him a lot, but that was one of my, Super early into my job there. Like I, I learned that that was You're very

291
00:51:00,000 --> 00:00:00,000
Shreya: Yeah, I appreciate that. So I think like that is definitely one of the things. I think other ones are kind of like more out of like curiosity because of like some ML problems that I worked on in the past. Like I,  I mentioned that I worked on a efficient ml, so looking into like how people are doing, like more efficient inference.

296
00:52:00,000 --> 00:00:00,000
And it's a big kind of experimentation framework. It's like understanding like where the bottlenecks are. So it's very, it's  very. You know, exploratory and experimental in nature. And so it's hard to kind of like be prescriptive about this is exactly what would work. It like, truly depends, like use case to use case architecture to architecture, hardware to hardware, et cetera.

306
00:53:00,000 --> 00:00:00,000
Shreya: I was testing on my co-pilot, so I  just got upgrade my laptop and then setting up vs code. And then I got co-pilot labs, I think is it?

317
00:54:00,000 --> 00:00:00,000
Where you have like code and then you have like test to make sure the code work. And like you have this like, kind of like iterative loop until you refinement, until you're able to kind of  like self-heal code or like automatically generate code. I think like that is super

323
00:55:00,000 --> 00:00:00,000
Yeah. Yeah, it's cool. It's really cool. It's basically like self-healing code. Yeah. You just let it run and then it makes a mistake and runs in a REPL, takes the code and ask it to just give you the diff and  like drops out the code and runs it again. It just

330
00:56:00,000 --> 00:00:00,000
Shreya: Hmm. Yeah. Not to be a downer, but I do think that like how hard it is to truly take these things to production and like get consistently amazing user experiences from it. But I think like this, yeah, we're at that stage where there's basically like a little bit of a gap between like what, what you kind of  see as being very exciting.

338
00:57:00,000 --> 00:00:00,000
I want it to be like tours and short and I want it to like I wanted to have context of like a previous history and maybe some  other like links, et cetera that I'm adding. So I wanted to hook it up to like, some of my data sources and do that. I think that would, I would like pay Yeah.

345
00:58:00,000 --> 00:00:00,000
There's some things Paul Graham would not  say that it writes in the, in the emails, but overall I would say probably like 20% of the drafts it creates are like, Usually good to go, like 70% it needs some work. And then there's like the 10% that is like, I have no idea why you just said that. It's completely like out of left field.

350
00:59:00,000 --> 00:00:00,000
Alessio: Yeah. No, no, no. Definitely. I think sometimes it doesn't understand the, the email is not a pitch, so somebody emails me something that's like unrelated and then it's like, oh, thank you.

354
01:00:00,000 --> 00:00:00,000
Alessio: I just give it the tread and then a blank blank slate. I don't give it anything else because I wanted to run while I'm not in the inbox, but yours. It's a little better. What I'm doing is draft generation. What you wanna do is like draft expansion. So instead of looking at the  inbox in your case, you will look at the draft folder and look through each draft and expend the draft.

363
01:01:00,000 --> 00:00:00,000
And if something hasn't been mentioned, don't add context about that. So that would probably be a generic gar that I could, I could add. And then you, you could probably configure it with like, what are the sets of like  follow up action items that you typically have and, and correct for it that way.

369
01:02:00,000 --> 00:00:00,000
So this kind of like obviously I'm biased because I feel this way because I've designed guardrails this way that it kind of like merges LLMs with rules and heuristics and like traditional ML, et cetera. But I do think  that like this, this general framework of like thinking about how to build ML products is something that I'm bullish on and something I'd want people to like think about as well.

