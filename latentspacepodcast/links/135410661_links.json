{"MPT": "https://www.latent.space/p/mosaic-mpt-7b", "LLaMA": "https://www.latent.space/p/llama2#details", "here": "https://lu.ma/llm-paper-club", "FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness": "https://arxiv.org/abs/2205.14135", "episode with Jonathan Frankle": "https://www.latent.space/p/mosaic-mpt-7b#details", "FlashAttention-2": "https://crfm.stanford.edu/2023/07/17/flash2.html", "Together AI": "https://www.together.xyz/", "From Deep Learning to Long Learning": "https://hazyresearch.stanford.edu/blog/2023-03-27-long-learning", "The Hardware Lottery by Sara Hooker": "https://hardwarelottery.github.io/", "Hazy Research": "https://hazyresearch.stanford.edu/", "Is Attention All You Need?": "https://www.isattentionallyouneed.com/", "Nvidia CUTLASS 3": "https://github.com/NVIDIA/cutlass/discussions/787", "SRAM scaling slows": "https://www.tomshardware.com/news/no-sram-scaling-implies-on-more-expensive-cpus-and-gpus", "S4": "https://hazyresearch.stanford.edu/blog/2022-06-11-simplifying-s4", "Hyena": "https://hazyresearch.stanford.edu/blog/2023-03-07-hyena", "Recurrent Neural Networks (RNNs)": "https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-recurrent-neural-networks", "Decibel Partners": "https://decibel.vc/", "Share this episode": "https://www.latent.space/p/flashattention?utm_source=substack&utm_medium=podcast&utm_content=share&action=share&token=eyJ1c2VyX2lkIjoxNzgyNTk4MCwicG9zdF9pZCI6MTM1NDEwNjYxLCJpYXQiOjE2OTA2OTI3NDYsImV4cCI6MTY5MzI4NDc0NiwiaXNzIjoicHViLTEwODQwODkiLCJzdWIiOiJwb3N0LXJlYWN0aW9uIn0.UM_hqU_GsdQjNVvaTCcJ2_BLqSrF5xkO64OGE3lS210&utm_campaign=CTA_3"}