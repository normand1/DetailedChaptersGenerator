{"FlashAttention": "https://arxiv.org/abs/2205.14135", "FasterTransformer": "https://github.com/NVIDIA/FasterTransformer", "dolly_hhrlhf": "https://huggingface.co/datasets/mosaicml/dolly_hhrlhf", "see our Dolly episode for more details": "https://www.latent.space/p/mike-conover#details", "ShareGPT-Vicuna": "https://huggingface.co/datasets/jeffwan/sharegpt_vicuna", "HC3": "https://huggingface.co/datasets/Hello-SimpleAI/HC3", "Alpaca": "https://huggingface.co/datasets/tatsu-lab/alpaca", "Helpful and Harmless": "https://huggingface.co/datasets/Anthropic/hh-rlhf", "Evol-Instruct": "https://huggingface.co/datasets/victor123/evol_instruct_70k", "books3 dataset": "https://huggingface.co/datasets/the_pile_books3", "ALiBi": "https://arxiv.org/abs/2108.12409", "LLM Foundry": "https://github.com/mosaicml/llm-foundry", "Jonathan Frankle": "http://www.jfrankle.com/", "Abhinav Venigalla": "https://www.linkedin.com/in/avenigalla", "such an important yet dark art": "https://twitter.com/swyx/status/1653064637611651077", "Introducing MPT-7B": "https://www.mosaicml.com/blog/mpt-7b", "Cerebras": "https://www.cerebras.net/", "Lottery Ticket Hypothesis": "https://arxiv.org/abs/1803.03635", "Hazy Research": "https://hazyresearch.stanford.edu/", "Flash Attention": "https://arxiv.org/abs/2205.14135", "https://twitter.com/code_star/status/1661386844250963972": "https://twitter.com/code_star/status/1661386844250963972?s=46&t=90xQ8sGy63D2OtiaoGJuww", "What is Sparsity?": "https://blogs.nvidia.com/blog/2020/05/14/sparsity-ai-inference/", "Hungry Hungry Hippos": "https://arxiv.org/abs/2212.14052", "BF16 FP": "https://en.wikipedia.org/wiki/Bfloat16_floating-point_format", "Share this episode": "https://www.latent.space/p/mosaic-mpt-7b?utm_source=substack&utm_medium=podcast&utm_content=share&action=share&token=eyJ1c2VyX2lkIjoxNzgyNTk4MCwicG9zdF9pZCI6MTIyNTY3MTI0LCJpYXQiOjE2OTA3MzgzOTAsImV4cCI6MTY5MzMzMDM5MCwiaXNzIjoicHViLTEwODQwODkiLCJzdWIiOiJwb3N0LXJlYWN0aW9uIn0.6R6KcxQRVZXtiD3NffUgct0X_3m9o_RqURfoF57aElI&utm_campaign=CTA_3"}